{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_5 = np.loadtxt('./train5_oddYr.txt',dtype = float)\n",
    "five_labels = np.ones((train_5.shape[0],1)) # these will be zeros\n",
    "\n",
    "train_3 = np.loadtxt('./train3_oddYr.txt',dtype = float)\n",
    "three_labels = np.zeros((train_3.shape[0],1)) # these are the ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_5[0].reshape((8,8)), cmap  = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.vstack((train_3,train_5))\n",
    "target_data = np.vstack((three_labels,five_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log likelihood: $L = \\sum^{T}{y_t\\log{\\sigma_{wx}}+(1-y_t)\\log{\\sigma_{-wx}}}$\n",
    "\n",
    "##### Update Rule: \n",
    "\n",
    "$W_{i+1} = W_i + \\eta(\\sum^{T}{(y_t - \\sigma_{wx})*x_{it}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(weights,x,b):\n",
    "    sig = (1/(1+math.exp(-1*weights@x+b)))\n",
    "    return(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(input_data,target_data,weights):\n",
    "    L = 0\n",
    "    for i in range(len(train_data)):\n",
    "        L += (target_data[i]*math.log(sigmoid(weights,input_data[i]))+\\\n",
    "             (1-target_data[i])*math.log(sigmoid(weights,-1*input_data[i])))   \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# routine to use the errors to calculate the weight update\n",
    "def calc_grad(weights,train_data,target_data):\n",
    "\n",
    "    dL_dWi = np.zeros((len(weights)))\n",
    "    for i in range(len(weights)):\n",
    "        grad_update = 0                   # stores our total weight updates       \n",
    "        for t in range(len(target_data)): # iterate over all of the data_ppoints\n",
    "        \n",
    "            # dL_dWi = (y_t - sigma(wx_t))*x_it\n",
    "            delta = (target_data[t] - sigmoid(weights,train_data[t]))\\\n",
    "                    *train_data[t,i]\n",
    "            grad_update +=delta           # accumulate the weight update over samples\n",
    "            \n",
    "        # after seeing the whole set, update the weight for the ith weight element\n",
    "        dL_dWi[i]=grad_update \n",
    "        \n",
    "    return dL_dWi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(input_data,target_data,weights):\n",
    "    y_pred = sigmoid(weights,input_data)\n",
    "    if y_pred > .5:\n",
    "        y_pred = 1\n",
    "    else:\n",
    "        y_pred = 0\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Update Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: likelihood: -11214.831757  accuracy: 0.500000\n",
      "iteration 20: likelihood: -5687.192262  accuracy: 0.500000\n",
      "iteration 40: likelihood: -1186.064471  accuracy: 0.611429\n",
      "iteration 60: likelihood: -736.553472  accuracy: 0.758571\n",
      "iteration 80: likelihood: -674.706778  accuracy: 0.783571\n",
      "iteration 100: likelihood: -627.398417  accuracy: 0.811429\n",
      "iteration 120: likelihood: -588.928272  accuracy: 0.827143\n",
      "iteration 140: likelihood: -556.952564  accuracy: 0.835714\n",
      "iteration 160: likelihood: -529.888098  accuracy: 0.847143\n",
      "iteration 180: likelihood: -506.630923  accuracy: 0.850714\n",
      "iteration 200: likelihood: -486.390842  accuracy: 0.858571\n",
      "iteration 220: likelihood: -468.587949  accuracy: 0.862857\n",
      "iteration 240: likelihood: -452.786711  accuracy: 0.872143\n",
      "iteration 260: likelihood: -438.653089  accuracy: 0.875000\n",
      "iteration 280: likelihood: -425.926039  accuracy: 0.879286\n",
      "iteration 300: likelihood: -414.398136  accuracy: 0.883571\n",
      "iteration 320: likelihood: -403.902132  accuracy: 0.889286\n",
      "iteration 340: likelihood: -394.301414  accuracy: 0.890714\n",
      "iteration 360: likelihood: -385.483116  accuracy: 0.892857\n",
      "iteration 380: likelihood: -377.353043  accuracy: 0.895714\n",
      "iteration 400: likelihood: -369.831874  accuracy: 0.897857\n",
      "iteration 420: likelihood: -362.852272  accuracy: 0.901429\n",
      "iteration 440: likelihood: -356.356661  accuracy: 0.903571\n",
      "iteration 460: likelihood: -350.295485  accuracy: 0.903571\n",
      "iteration 480: likelihood: -344.625834  accuracy: 0.907143\n",
      "iteration 500: likelihood: -339.310354  accuracy: 0.906429\n",
      "iteration 520: likelihood: -334.316358  accuracy: 0.909286\n",
      "iteration 540: likelihood: -329.615115  accuracy: 0.911429\n",
      "iteration 560: likelihood: -325.181258  accuracy: 0.913571\n",
      "iteration 580: likelihood: -320.992300  accuracy: 0.916429\n",
      "iteration 600: likelihood: -317.028235  accuracy: 0.917143\n",
      "iteration 620: likelihood: -313.271200  accuracy: 0.917857\n",
      "iteration 640: likelihood: -309.705192  accuracy: 0.919286\n",
      "iteration 660: likelihood: -306.315830  accuracy: 0.920000\n",
      "iteration 680: likelihood: -303.090155  accuracy: 0.920714\n",
      "iteration 700: likelihood: -300.016452  accuracy: 0.922143\n",
      "iteration 720: likelihood: -297.084108  accuracy: 0.922857\n",
      "iteration 740: likelihood: -294.283482  accuracy: 0.924286\n",
      "iteration 760: likelihood: -291.605796  accuracy: 0.924286\n",
      "iteration 780: likelihood: -289.043037  accuracy: 0.924286\n",
      "iteration 800: likelihood: -286.587880  accuracy: 0.923571\n",
      "iteration 820: likelihood: -284.233611  accuracy: 0.923571\n",
      "iteration 840: likelihood: -281.974066  accuracy: 0.926429\n",
      "iteration 860: likelihood: -279.803574  accuracy: 0.927143\n",
      "iteration 880: likelihood: -277.716912  accuracy: 0.929286\n",
      "iteration 900: likelihood: -275.709255  accuracy: 0.930000\n",
      "iteration 920: likelihood: -273.776146  accuracy: 0.930000\n",
      "iteration 940: likelihood: -271.913455  accuracy: 0.931429\n",
      "iteration 960: likelihood: -270.117354  accuracy: 0.932857\n",
      "iteration 980: likelihood: -268.384288  accuracy: 0.932857\n",
      "iteration 1000: likelihood: -266.710949  accuracy: 0.933571\n",
      "iteration 1020: likelihood: -265.094259  accuracy: 0.934286\n",
      "iteration 1040: likelihood: -263.531347  accuracy: 0.935714\n",
      "iteration 1060: likelihood: -262.019534  accuracy: 0.935000\n",
      "iteration 1080: likelihood: -260.556315  accuracy: 0.935000\n",
      "iteration 1100: likelihood: -259.139346  accuracy: 0.935000\n",
      "iteration 1120: likelihood: -257.766433  accuracy: 0.935714\n",
      "iteration 1140: likelihood: -256.435518  accuracy: 0.936429\n",
      "iteration 1160: likelihood: -255.144668  accuracy: 0.937143\n",
      "iteration 1180: likelihood: -253.892069  accuracy: 0.937143\n",
      "iteration 1200: likelihood: -252.676013  accuracy: 0.937143\n",
      "iteration 1220: likelihood: -251.494893  accuracy: 0.937143\n",
      "iteration 1240: likelihood: -250.347196  accuracy: 0.937143\n",
      "iteration 1260: likelihood: -249.231493  accuracy: 0.937857\n",
      "iteration 1280: likelihood: -248.146438  accuracy: 0.937857\n",
      "iteration 1300: likelihood: -247.090756  accuracy: 0.939286\n",
      "iteration 1320: likelihood: -246.063245  accuracy: 0.940714\n",
      "iteration 1340: likelihood: -245.062766  accuracy: 0.940714\n",
      "iteration 1360: likelihood: -244.088242  accuracy: 0.942143\n",
      "iteration 1380: likelihood: -243.138650  accuracy: 0.943571\n",
      "iteration 1400: likelihood: -242.213023  accuracy: 0.942857\n",
      "iteration 1420: likelihood: -241.310442  accuracy: 0.942857\n",
      "iteration 1440: likelihood: -240.430035  accuracy: 0.943571\n",
      "iteration 1460: likelihood: -239.570971  accuracy: 0.943571\n",
      "iteration 1480: likelihood: -238.732465  accuracy: 0.943571\n",
      "iteration 1500: likelihood: -237.913765  accuracy: 0.943571\n",
      "iteration 1520: likelihood: -237.114159  accuracy: 0.944286\n",
      "iteration 1540: likelihood: -236.332967  accuracy: 0.945000\n",
      "iteration 1560: likelihood: -235.569541  accuracy: 0.945000\n",
      "iteration 1580: likelihood: -234.823263  accuracy: 0.945714\n",
      "iteration 1600: likelihood: -234.093544  accuracy: 0.945714\n",
      "iteration 1620: likelihood: -233.379822  accuracy: 0.945714\n",
      "iteration 1640: likelihood: -232.681560  accuracy: 0.945714\n",
      "iteration 1660: likelihood: -231.998244  accuracy: 0.945714\n",
      "iteration 1680: likelihood: -231.329383  accuracy: 0.945714\n",
      "iteration 1700: likelihood: -230.674508  accuracy: 0.945714\n",
      "iteration 1720: likelihood: -230.033169  accuracy: 0.945714\n",
      "iteration 1740: likelihood: -229.404937  accuracy: 0.946429\n",
      "iteration 1760: likelihood: -228.789399  accuracy: 0.947143\n",
      "iteration 1780: likelihood: -228.186160  accuracy: 0.947857\n",
      "iteration 1800: likelihood: -227.594841  accuracy: 0.949286\n",
      "iteration 1820: likelihood: -227.015079  accuracy: 0.949286\n",
      "iteration 1840: likelihood: -226.446526  accuracy: 0.949286\n",
      "iteration 1860: likelihood: -225.888847  accuracy: 0.949286\n",
      "iteration 1880: likelihood: -225.341721  accuracy: 0.949286\n",
      "iteration 1900: likelihood: -224.804838  accuracy: 0.950000\n",
      "iteration 1920: likelihood: -224.277903  accuracy: 0.950000\n",
      "iteration 1940: likelihood: -223.760629  accuracy: 0.950000\n",
      "iteration 1960: likelihood: -223.252742  accuracy: 0.950000\n",
      "iteration 1980: likelihood: -222.753978  accuracy: 0.950000\n",
      "iteration 2000: likelihood: -222.264083  accuracy: 0.950000\n",
      "iteration 2020: likelihood: -221.782812  accuracy: 0.950000\n",
      "iteration 2040: likelihood: -221.309928  accuracy: 0.949286\n",
      "iteration 2060: likelihood: -220.845205  accuracy: 0.950000\n",
      "iteration 2080: likelihood: -220.388423  accuracy: 0.950714\n",
      "iteration 2100: likelihood: -219.939371  accuracy: 0.950000\n",
      "iteration 2120: likelihood: -219.497846  accuracy: 0.950714\n",
      "iteration 2140: likelihood: -219.063650  accuracy: 0.950714\n",
      "iteration 2160: likelihood: -218.636594  accuracy: 0.950714\n",
      "iteration 2180: likelihood: -218.216495  accuracy: 0.951429\n",
      "iteration 2200: likelihood: -217.803175  accuracy: 0.951429\n",
      "iteration 2220: likelihood: -217.396463  accuracy: 0.951429\n",
      "iteration 2240: likelihood: -216.996194  accuracy: 0.951429\n",
      "iteration 2260: likelihood: -216.602209  accuracy: 0.950714\n",
      "iteration 2280: likelihood: -216.214352  accuracy: 0.951429\n",
      "iteration 2300: likelihood: -215.832475  accuracy: 0.951429\n",
      "iteration 2320: likelihood: -215.456432  accuracy: 0.951429\n",
      "iteration 2340: likelihood: -215.086085  accuracy: 0.952143\n",
      "iteration 2360: likelihood: -214.721296  accuracy: 0.952143\n",
      "iteration 2380: likelihood: -214.361937  accuracy: 0.952143\n",
      "iteration 2400: likelihood: -214.007878  accuracy: 0.952143\n",
      "iteration 2420: likelihood: -213.658997  accuracy: 0.952143\n",
      "iteration 2440: likelihood: -213.315176  accuracy: 0.952143\n",
      "iteration 2460: likelihood: -212.976298  accuracy: 0.951429\n",
      "iteration 2480: likelihood: -212.642251  accuracy: 0.951429\n",
      "iteration 2500: likelihood: -212.312927  accuracy: 0.951429\n",
      "iteration 2520: likelihood: -211.988220  accuracy: 0.952857\n",
      "iteration 2540: likelihood: -211.668028  accuracy: 0.952857\n",
      "iteration 2560: likelihood: -211.352252  accuracy: 0.952857\n",
      "iteration 2580: likelihood: -211.040796  accuracy: 0.952857\n",
      "iteration 2600: likelihood: -210.733566  accuracy: 0.952857\n",
      "iteration 2620: likelihood: -210.430471  accuracy: 0.952857\n",
      "iteration 2640: likelihood: -210.131423  accuracy: 0.952857\n",
      "iteration 2660: likelihood: -209.836336  accuracy: 0.952857\n",
      "iteration 2680: likelihood: -209.545128  accuracy: 0.952857\n",
      "iteration 2700: likelihood: -209.257717  accuracy: 0.952143\n",
      "iteration 2720: likelihood: -208.974024  accuracy: 0.951429\n",
      "iteration 2740: likelihood: -208.693974  accuracy: 0.951429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2760: likelihood: -208.417492  accuracy: 0.951429\n",
      "iteration 2780: likelihood: -208.144505  accuracy: 0.952143\n",
      "iteration 2800: likelihood: -207.874943  accuracy: 0.952143\n",
      "iteration 2820: likelihood: -207.608738  accuracy: 0.952143\n",
      "iteration 2840: likelihood: -207.345824  accuracy: 0.952857\n",
      "iteration 2860: likelihood: -207.086135  accuracy: 0.952857\n",
      "iteration 2880: likelihood: -206.829608  accuracy: 0.952857\n",
      "iteration 2900: likelihood: -206.576181  accuracy: 0.952857\n",
      "iteration 2920: likelihood: -206.325796  accuracy: 0.952857\n",
      "iteration 2940: likelihood: -206.078393  accuracy: 0.953571\n",
      "iteration 2960: likelihood: -205.833916  accuracy: 0.953571\n",
      "iteration 2980: likelihood: -205.592309  accuracy: 0.953571\n",
      "iteration 3000: likelihood: -205.353519  accuracy: 0.954286\n"
     ]
    }
   ],
   "source": [
    "# initialize random weights\n",
    "import math\n",
    "L = 0\n",
    "weights = np.random.uniform(size = len(train_data[0]))\n",
    "learning_rate = .02/800\n",
    "\n",
    "\n",
    "for i in range(3001):\n",
    "    # calculate log likelihood\n",
    "    like = likelihood(train_data,target_data,weights=weights)\n",
    "\n",
    "    # calculate our prediction accuracy for our set\n",
    "    accuracy = 0\n",
    "    for j in range(len(target_data)):\n",
    "        y_pred = predict_y(train_data[j],target_data[j],\n",
    "                           weights=weights) # returns 0 or 1\n",
    "        \n",
    "        if y_pred == target_data[j]:\n",
    "            accuracy +=1\n",
    "        \n",
    "    # normalize the accuracy - out of 1400\n",
    "    accuracy=accuracy/len(target_data)\n",
    "    \n",
    "    # calculate the gradient of the weights\n",
    "    dW = calc_grad(weights,train_data,target_data)\n",
    "    #update the weights\n",
    "    weights = weights + learning_rate*dW\n",
    "    \n",
    "    if i%20 == 0:\n",
    "        print('iteration %i: likelihood: %f  accuracy: %f'%(i,like,accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_weights = np.reshape(weights,(8,8))\n",
    "\n",
    "plt.imshow(vis_weights,cmap = 'gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_5 = np.loadtxt('./test5_oddYr.txt',dtype = float)\n",
    "five_labels_test = np.ones((test_5.shape[0],1)) # these will be zeros\n",
    "\n",
    "test_3 = np.loadtxt('./test3_oddYr.txt',dtype = float)\n",
    "three_labels_test = np.zeros((test_3.shape[0],1)) # these are the ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.vstack((test_3,test_5))\n",
    "test_target = np.vstack((three_labels_test,five_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(test_input)):\n",
    "\n",
    "    # returns 0 or 1\n",
    "    y_pred = predict_y(test_input[i],test_target[i],weights=weights) \n",
    "\n",
    "    if y_pred == test_target[i]:\n",
    "        accuracy +=1\n",
    "        \n",
    "\n",
    "percent_accuracy = accuracy/len(test_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94875"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
